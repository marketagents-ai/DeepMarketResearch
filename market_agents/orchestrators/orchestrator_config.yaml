# orchestrator_config.yaml

num_agents: 2
max_rounds: 1
environment_order:
  - web_research
#  - group_chat
#  - research
tool_mode: true
agent_config:
  knowledge_base: "hamlet_kb"
  use_llm: true
llm_configs:
    - name: "gpt-4o"
      model: "gpt-4o"
      client: "openai"
      max_tokens: 4096
      temperature: 0.7
      use_cache: true
#    - name: "claude"
#      model: "claude-3-5-sonnet-latest"
#      client: "anthropic"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "hermes"
#      model: "openai/NousResearch/DeepHermes-3-Llama-3-8B-Preview"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "deepseek"
#      model: "openai/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "qwq"
#      model: "openai/Qwen/QwQ-32B-Preview"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "qwen"
#      model: "openai/Qwen/Qwen2.5-7B-Instruct"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true

environment_configs:
  group_chat:
    name: "group_chat"
    api_url: "http://localhost:8002"
  #  initial_topic: "Initial Market Discussion"
    initial_topic: "What will be the Fed's rate decision in March 2024 FOMC meeting?"
    sub_rounds: 2
    group_size: 4

  research:
    name: "market_research"
    api_url: "http://localhost:8003"
#    initial_topic: "Market Analysis"
    initial_topic: "What will be the Fed's rate decision in March 2024 FOMC meeting?"
    sub_rounds: 2
    group_size: 4
    schema_model: "FedRateAnalysis"

  web_research:
    name: "web_research"
    api_url: "http://localhost:8005"
    initial_query: "What will be the Fed's rate decision in March 2024 FOMC meeting?"
    sub_rounds: 1
    schema_model: "FedRateAnalysis"
    search_config:
      max_concurrent_requests: 50
      rate_limit: 0.1
      content_max_length: 4000
      request_timeout: 30
      urls_per_query: 2
      use_ai_summary: true
      methods: 
        - "selenium"
        - "playwright"
        - "beautifulsoup"
        - "newspaper3k"
        - "scrapy"
        - "requests_html"
        - "mechanicalsoup"
        - "httpx"
      default_method: "newspaper3k"
      headers:
        User-Agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
        Accept-Language: "en-US,en;q=0.5"

protocol: "acl_message"
database_config:
  db_host: "localhost"
  db_port: "5433"

request_limits:
  openai:
    max_requests_per_minute: 500
    max_tokens_per_minute: 40000
  anthropic:
    max_requests_per_minute: 300
  vllm:
    max_requests_per_minute: 150
    max_tokens_per_minute: 50000
  litellm:
    max_requests_per_minute: 100
    max_tokens_per_minute: 35000